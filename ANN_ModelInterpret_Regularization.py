# -*- coding: utf-8 -*-
"""ai2-c1-hw1-students.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DG6mLWllvDVJiU74ipwYvAX_MHLFezho

# AI-2: Convolutional Neural Network
## Project-Essentials: Artificial Neural Networks, Model Interpretation, and Regularization

**Member of team: Rampunit Kumar, Puru Sharma, Pallavi Sikha**

**AI2 **<br/>
**PROJECT-AI**<br/>
**Instructor**: Ignacio Becker GERMANY<br />
**Maximum Score**: 100

<hr style="height:2.4pt">
"""

#RUN THIS CELL
import requests
from IPython.core.display import HTML

# Commented out IPython magic to ensure Python compatibility.
import requests
from IPython.core.display import HTML
import random
random.seed(112358)
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.preprocessing.image import ImageDataGenerator
import warnings
warnings.filterwarnings("ignore")
import os
import sys
from keras.models import Sequential
from keras.layers.core import Lambda, Dense, Flatten, Dropout
from keras.callbacks import EarlyStopping
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
from numpy import asarray
from numpy import clip
from PIL import Image
import requests
from IPython.core.display import HTML
from numpy import asarray
from numpy import clip
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.inspection import permutation_importance
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample
from tensorflow.keras import layers
from tensorflow.keras import models
from sklearn.metrics import mean_squared_error
from tensorflow.keras import optimizers
from tensorflow.keras import regularizers
from sklearn.model_selection import train_test_split
import base64
import pandas as pd
from IPython.display import HTML
from sklearn import preprocessing
from google.colab import drive
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
import random
random.seed(112358)

import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

from sklearn.inspection import permutation_importance
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample

# TensorFlow and tf.keras
import tensorflow as tf

# %matplotlib inline

"""### INSTRUCTIONS


- This homework is a jupyter notebook. Download and work on it on your local machine.

- This homework should be submitted in pairs.

- Ensure you and your partner together have submitted the homework only once. Multiple submissions of the same work will be penalised and will cost you 2 points.

- Please restart the kernel and run the entire notebook again before you submit.

- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit.

- To submit the homework, either one of you upload the working notebook on edStem and click the submit button on the bottom right corner.

- Submit the homework well before the given deadline. Submissions after the deadline will not be graded.

- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them.

- Comment your code well. This would help the graders in case there is any issue with the notebook while running. It is important to remember that the graders will not troubleshoot your code.

- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**.

- In questions that require code to answer, such as "calculate the $R^2$", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example:
```
print(f'The R^2 is {R:.4f}')
```
- Your plots should include clear labels for the $x$ and $y$ axes as well as a descriptive title ("MSE plot" is not a descriptive title; "95 % confidence interval of coefficients of polynomial degree 5" is).

- **Ensure you make appropraite plots for all the questions it is applicable to, regardless of it being explicitly asked for.**

<hr style="height:2pt">

### Names of the people who worked on this homework together
#### /name here/

<a id="contents"></a>

## Notebook Contents

- [**PART 1 [40 pts]: Model interpretation and predictive intervals in NN**](#part1)
  - [Overview and Data Description](#part1intro)
  - [Questions](#part1questions)
  - [Solutions](#part1solutions)


- [**PART 2.1 [30 pts]: Kannada MNIST Kaggle competition using ANNs**](#part2.1)
  - [Problem Statement](#part2.1intro)
  - [The Kannada MNIST Dataset](#part2.1about)
  - [Downloading the Data Files](#part2.1data)
  - [AI2-C2 Homework Kaggle Competition](#part2.1kaggle)
  - [Questions](#part2.1questions)
  - [Solutions](#part2.1solutions)

- [**PART 2.2 [30 pts]: Kannada MNIST using CNNs**](#part2)
  - [Questions](#part2.2questions)
  - [Solutions](#part2.2solutions)

---

<div class="alert alert-block alert-danger" style="color:black;background-color:#E7F4FA">
<h1> PART 1 [40 pts]: Model interpretation and predictive intervals in NN </h1>

<a id="part1intro"></a>

<b> Overview and Data Description </b>

In this problem, you will be building and interpreting models to predict whether a flight was delayed for its arrival based on features that could be measured as the flight takes off.  
We will also estimate the predictive intervals of the model using bootstrapping. We will utilize those predictive intervals to build a new kind of model: a model that refrains from making a prediction when it is not confident.  

The included variables are:

**ARRIVAL_DELAY**: the difference between scheduled arrival and actual arrival, in minutes (positive is late, negative is early).

**DISTANCE**: the distance between arrival and departure airports, in miles.

**SCHEDULED_TIME**: the flight's scheduled travel time.

**MONTH**: the month the flight took off, 1 = January, 2 = February, etc.

**SCHED_DEP_HOUR**: the scheduled departure time (the hour of the day).

**SCHED_ARR_HOUR**: the scheduled arrival time (the hour of the day).

**FLIGHT_COUNT**: the number of flights flying out of that airport before noon on a typical day.

**DAY_OF_WEEK**: the day of the week, 1 = Monday, 2 = Tuesday, etc.

**ORIGIN_AIRPORT**: the airport the flight took off from.

**DESTINATION_AIRPORT**: the airport the flight was scheduled to land at.

For the airport codes, see: https://www.bts.gov/topics/airlines-and-airports/world-airport-codes

To sucessfully complete this part, you will proceed by fitting a NN model, evaluating its accuracy, interpreting the predictors' importance, and finally evaluating the predictive intervals.

**NOTE:** The observations were sampled so that roughly half of the observations were delayed and half of the observations were not delayed.

</div>

<div class="alert alert-block alert-danger" style="color:black;background-color:#E7F4FA">

<h2>PART 1: Questions</h2>

**1.1.1 [2 points]**  Read in the dataset `flights.csv`. Create a variable `DELAY_OR_NOT` that denotes whether `ARRIVAL_DELAY` is greater than or equal to 15 minutes (the FAA and BTS define a flight as delayed only if it arrives 15 minutes late or more). This is going to be the response variable for the rest of this question.

**1.1.2 [2 points]** Preprocess the data: one-hot-encode the non-numeric categorical variables, deal with missing values if there are any, scale your data, and split the data into training and test sets (use an 80/20 split with `random_state=111`). Print the resulting shapes of your $X$ and $y$ dataframes for both your train and your test sets.

**1.2 [2 points]** Fit an artificial neural network model using all predictors (name this model `NN_model`).  Use a dense feed-forward network with two hidden layers with 15 nodes in each hidden layer. For this network, use appropriate activation functions for each layer, select an appropriate loss function and optimizer, specify a validation split of 0.2, train for an appropriate number of epochs based on the results of your training and validation accuracy plot, and feel free to use the default batch size while training. Plot the training accuracy and validation accuracy as a function of epochs from your `NN_model` training history. Evaluate the `NN_model` model on both train and test, and print out the resulting train and test accuracies.

**1.3 [10 points]** To begin our interpretation of the resulting `NN_model`, we will first use a "proxy model" that we know how to interpret and train it on our `NN_model` training predictions.

- **1.3.1** For this we need to modify our training set. First, generate a set of `NN_model` class predictions for the training set. These training predictions will be used to form a revised training dataset for our proxy model: (a) use all of the same $X$ values used by `NN_model` for our $X$ train and (b) replace the actual response values $y$ with the predicted $\hat{y}$ values generated by the fitted `NN_model`.

- **1.3.2** Next, fit a logistic regression model using your revised training dataset from 1.3.1 (name this model `logreg`). Use ridge-like regularization. Print the `logreg` test accuracy to confirm that it is similar to what we saw for our `NN_model` test accuracy in 1.2. You may need to adjust `C` in order to achieve a similar accuracy.

- **1.3.3** Now use sklearn's `permutation_importance` class (already included in this notebook's imports) to compute the feature importance using the `logreg` model.

  - Read the official documentation for `permutation_importance` [here](https://scikit-learn.org/stable/modules/permutation_importance.html#:~:text=The%20permutation%20feature%20importance%20is,model%20depends%20on%20the%20feature.) as well as [here](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance) to learn how it works.

  - You can use the default number of `n_repeats` and your estimator's default `scorer`. To speed up the time it takes to run your permutations, you can try setting `n_jobs=-1` to take full advantage of all of your available processor cores.

  - Measure the **relative** variable importance (i.e. as a proportion of the variable importance of the most important variable identified by `permutation_importance`) and generate a barplot illustrating the relative variable importances for the top-10 most important predictors identified using `permutation_importance`.

**1.4 [10 points]** Another way to interpret the  `NN_model` is by examining the response as a function of any of the predictors. Particularly, we will select from features often found most significant from the analysis above. **For all 1.4 plots below**, for ease of interpretation, **please be certain to** display all predictors on their original scales.

   - **1.4.1** Set all predictors to their means/modes except for `SCHED_DEP_HOUR`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` on the data from the **training set**. Interpret what you see in 2-4 sentences.
   - **1.4.2** Set all predictors to their means/modes except for `SCHED_DEP_HOUR` and `FLIGHT_COUNT`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` and `FLIGHT_COUNT` from the training set (see the question 1.4 "HINT" below).

   - **1.4.3**   Set all predictors to their means/modes except for except for `SCHED_DEP_HOUR` and `SCHED_ARR_HOUR`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` and `SCHED_ARR_HOUR` from the training set.


   - **1.4.4** Set all predictors to their means/modes except for except for `SCHED_DEP_HOUR` and `DISTANCE`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` and `DISTANCE` from the training set.
  - **1.4.5** In 5-10 sentences, interpret what you have seen in 1.4.2, 1.4.3, and 1.4.4.
  
**HINT:** For 1.4.2, 1.4.3, and 1.4.4, when you include `SCHED_DEP_HOUR` on one axis and your second predictor on the other axis, you can color your datapoints based on their corresponding predicted probabilities by using  the `c` and `cmap` arguments in `plt.scatter`. You can also add a labeled colorbar to your plot to make clear what those colors mean. Please refer to the matplotlib documentation for examples.
    
**1.5 [2 points]**
    
In this part, we will attempt to do model inference. Neural Networks have too many parameters, and therefore inference on all the parameters is intractable and meaningless.

Using the same network architecture as `NN_model` (layers, nodes, activations, etc.) and your scaled data from that model, create multiple training sets using bootstrapping and fit a separate neural network model to each bootstrapped set of data (a minimum of at least 50 bootstraps should be used). Predict the output on the test data for each model. Randomly select 8 test observations and on 8 subplots, plot the distribution of predicted probabilities (i.e. $n$ bootstrapped probabilites) with the 95% CI bounds clearly marked and reported in each subplot and the actual class of each observation included in each subplot's title for easy reference.

Interpret what you see in 3-5 sentences.

    
**NOTE:** The code for this problem can take an extremely long time to execute. Please feel free to use the provided `progressbar` function below to visually track the progress of your bootstraps.
    
**1.6 [12 points]**
    
Using the probability distribution of the predictions obtained from the bootstrapped samples above, we can evaluate how "significant" our bagged (i.e. bootstrap-aggregated) prediction will be for each test observation.

To accomplish this, you will first calculate the ratio of bootstrapped probabilities that cross the threshold value of $\hat{p}=0.5$. Let's call this ratio the **Posterior Prediction Ratio (PPR)**. When a bagged prediction's $PPR=0$, all predictions are compatible (i.e. all bootstrapped probabilities for that test observation are on the same side of $\hat{p}=0.5$). Likewise, when the $PPR=0.5$, half of the bootstrapped predictions for that test observation are $\hat{y}=0$, and the other half are $\hat{y}=1$. After calculating your $PPR$ values for all test observations, you should have $n=2000$ $PPR$ values (i.e. one for each test observation).

Next, to get more accurate predictions, we can create an **abstain** model that will abstain from making a prediction for a particular observation if some defined threshold for significance (i.e. maximum $PPR$ value) is not met. (If you'd like to learn more about abstain models, you can read more [here](https://openreview.net/forum?id=rJxF73R9tX).)

Let's explore how your resulting test accuracies might change by using your bootstrapped prediction results from question 1.5 for an **abstain bagging model** (i.e. a bootstrap aggregated model where some test observations are simply not predicted based on a given $PPR$ threshold). You can make your abstain model *stricter* by using smaller $PPR$ threshold values.

- Print the test accuracy for your **bagging model** predictions from question 1.5 using predictions for all 2,000 of our test observations.

- Plot the test accuracies for an **abstain bagging model** using your predictions from question 1.5 as a function of increasing $PPR$.

- Also, plot the proportion of test observations not abstained (i.e. the proportion of those predicted) for your **abstain bagging model** as a function of increasing $PPR$.

- Interpret what you see in 3-5 sentences.

    
**NOTE**: You should observe that as $PPR$ decreases (more confident predictions), you must also compromise on the number of points that your abstain model predicts confidently.

</div>

<a id="part1solutions"></a>

## PART 1: Solutions

<div class='exercise-r'>  

**1.1**

</div>
"""

#Reading data and storing it in a dataframe
flights=pd.read_csv('flights.csv')
# Printing the head of the dataframe
flights.head()

# Defining response variable such that it take 1 value if ARRIVAL_DELAY greater than 15 min
DELAY_OR_NOT=(flights['ARRIVAL_DELAY']>=15)*1

# Dropping ARRIVAL_DELAY as this is used to generate the final output variable
flights.drop(["ARRIVAL_DELAY"],axis=1,inplace=True)

# Checking the head of dataframe
flights.head()

# Checking the shape of the dataframe
flights.shape

# Drawing the pair plots between features to find out any mulitcollinearity
display(sns.pairplot(flights,height=5, aspect=0.6))

"""<div class='exercise-r'>  

**1.1.2**
    
</div>
"""

# Finding missing values in all the features
flights.isnull().sum()

# Making a list of categorical features
# We will be using get_dummies() method for one hot encoding and we wil be using drop_first=True to prevent dummy variable trap
# Again inspecting the head of the encoded dataframe
categorical_columns=['ORIGIN_AIRPORT','DESTINATION_AIRPORT']
flights_encoded = pd.get_dummies(flights, columns = categorical_columns, drop_first=True)

# Again inspecting the head of the encoded dataframe
flights_encoded.head()

# Using train_test_split function to split the predictor dataframe and response variable into train and test sets
x_train,x_test,y_train,y_test=train_test_split(flights_encoded,DELAY_OR_NOT,train_size=0.8,random_state=111)

# We are scaling and normalising the input features using StandardScaler() method
scaler = StandardScaler()

# Fitting on the training data
scaler.fit(x_train)

# Scaling the training data and the test data using transform() method
x_train_scaled, x_test_scaled = scaler.transform(x_train), scaler.transform(x_test)
x_train_scaled_dataframe=pd.DataFrame(scaler.transform(x_train), index=x_train.index, columns=x_train.columns)
x_test_scaled_dataframe=pd.DataFrame(scaler.transform(x_test), index=x_test.index, columns=x_test.columns)

"""**1.2**"""

# build your NN
# Using the given number of hidden layers and parameters, we are building a neural network named "NN_model"
n_hidden=15
n_output=1
model=tf.keras.models.Sequential(name="NN_model")
model.add(tf.keras.layers.Dense(n_hidden,input_dim=808,activation = 'relu',name='hidden1'))
model.add(tf.keras.layers.Dense(n_hidden,activation = 'relu',name='hidden2'))
model.add(tf.keras.layers.Dense(n_output, activation = 'sigmoid',name='output'))

# Displaying the details of the neural network
model.summary()

# Using plot_model method to plot the architecture of the neural network
tf.keras.utils.plot_model(model, show_shapes=True)

# compile it and run it
# Compiling the neural network model with adam optimiser, loss function as binary_crossentropy(since this is binary classification), metric as accuracy
# Using metric as accuracy as we want to correctly predict if the flight is delayed or not
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

# Using fit() to train the model
history = model.fit(x_train_scaled,y_train, epochs = 10, batch_size = 10,verbose=0,validation_split=0.2)

# plot train and val acc as  a function of epochs
# your code here
fig, ax = plt.subplots(1,2,figsize = (20,5))
ax[0].plot(history.history['loss'],'r',label = 'Training Loss')
ax[0].plot(history.history['val_loss'],'b',label = 'Validation Loss')
ax[1].plot(history.history['accuracy'],'r',label = 'Training Accuracy')
ax[1].plot(history.history['val_accuracy'],'b',label = 'Validation Accuracy')
ax[0].legend()
ax[1].legend()
ax[0].set_xlabel('Epochs')
ax[1].set_xlabel('Epochs');
ax[0].set_ylabel('Loss')
ax[1].set_ylabel('Accuracy %');
fig.suptitle('Neural Network Training', fontsize = 24)

# We are finding out model's evaluation on the train and test set.
training_eval=model.evaluate(x_train_scaled,y_train)
test_eval=model.evaluate(x_test_scaled,y_test)

# We are evaluating the model on the training set and test set and printing the train and test accuracy
training_accuracy=training_eval[1]
test_accuracy=test_eval[1]
print(f'Training accuracy is {training_accuracy} and test accuracy is {test_accuracy}')

# Generating NN_model's prediction on the scaled train and test data
y_train_pred=model.predict(x_train_scaled)
y_test_pred=model.predict(x_test_scaled)
# Printing the predicted values roc_auc_score
print("NN_model_train_auc:", roc_auc_score(y_train, y_train_pred))
print("NN_model_test_auc:", roc_auc_score(y_test, y_test_pred))

"""<div class='exercise-r'>

**1.3**

</div>

**1.3.1**
"""

# Fit the logistic regression model
# Using the x_train_scaled as training data for proxy model using logistic regression
# Using y_train_prediction data from NN_model as training data for proxy model using logistic regression
proxy_model_xtrain=x_train_scaled
proxy_model_ytrain=y_train_pred

# Flattening and doing appropriate changes to proxy_model_ytrain which will make it suitable to pass into logistic regression model
proxy_model_logistic_ytrain=((proxy_model_ytrain)>=0.5)*1
proxy_model_logistic_ytrain.ravel()

"""**1.3.2**"""

# plot train and val acc as  a function of epochs
# Fitting the logistic regression model on training data
clf = LogisticRegression(C=0.0695,max_iter=5000)
clf.fit(proxy_model_xtrain,proxy_model_logistic_ytrain.ravel())
logistic_pred = clf.predict(x_test_scaled)

# Finding the accuracy score from logistic regression and trying to get accuracy close to the accuracy obtained from NN_model
accuracy_score(logistic_pred,y_test)

"""**1.3.3**"""

# Finding the permutation importance of features in our dataset
result1 = permutation_importance(clf, x_test_scaled, y_test, n_repeats=10,random_state=42,n_jobs=-1)

# Finding most important feature's value which will be used for finding relative importance
max_important_value=np.amax(result1.importances_mean)
print(f'The feature with the maximum value is {max_important_value}')

# Finding the relative importance of features by dividing each feature values with the most important feature value
relative_variable_importance=(result1.importances_mean/max_important_value)

#
feat_importances = pd.Series(relative_variable_importance, index=flights_encoded.columns)
f, ax = plt.subplots(figsize=(20,20))
feat_importances.nlargest(10).plot(kind='barh')
plt.title("Top 10 important features")
plt.show()

"""<div class='exercise-r'>

**1.4**    

**1.4.1**

</div>
"""

#
x_train_inter_1 = x_train.copy(deep=True)

#
for column in x_train_inter_1.columns:
  if(column!="SCHED_DEP_HOUR"):
    x_train_inter_1[column]=x_train_inter_1[column].mean()

# Now see the new dataframe
x_train_inter_1.head()

#similarly do for y_train
y_train_inter_1=model.predict(x_train_inter_1)
y_train_inter_1

plt.scatter(x_train_inter_1['SCHED_DEP_HOUR'],y_train_inter_1)

"""**INTERPRETATION:**

By the above graph we can interpret that majority of schedule departure are not delay and some are delay.
Also Schedule_departure hour is the important variable.

<div class='exercise-r'>

**1.4.2**
</div>
"""

# your code here
x_train_inter_2 = x_train.copy(deep=True)

#
for column in x_train_inter_2.columns:
  if(column!="SCHED_DEP_HOUR" and column!="FLIGHT_COUNT"):
    x_train_inter_2[column]=x_train_inter_2[column].mean()

y_train_inter_2=model.predict(x_train_inter_2)

y_train_inter_2

plt.scatter(x_train_inter_2["SCHED_DEP_HOUR"], x_train_inter_2["FLIGHT_COUNT"], c=y_train_inter_2, s=10, cmap='gray')
plt.gray()

"""<div class='exercise-r'>

**1.4.3**
    
</div>
"""

# your code here
x_train_inter_3 = x_train.copy(deep=True)

#
for column in x_train_inter_3.columns:
  if(column!="SCHED_DEP_HOUR" and column!="SCHED_ARR_HOUR"):
    x_train_inter_3[column]=x_train_inter_3[column].mean()

#
y_train_inter_3=model.predict(x_train_inter_3)

plt.scatter(x_train_inter_3["SCHED_DEP_HOUR"], x_train_inter_3["SCHED_ARR_HOUR"], c=y_train_inter_3, s=10, cmap='gray')
plt.gray()

"""<div class='exercise-r'>

**1.4.4**
    
</div>
"""

# your code here
x_train_inter_4 = x_train.copy(deep=True)

# your code here
for column in x_train_inter_4.columns:
  if(column!="SCHED_DEP_HOUR" and column!="DISTANCE"):
    x_train_inter_4[column]=x_train_inter_4[column].mean()

y_train_inter_4=model.predict(x_train_inter_4)

plt.scatter(x_train_inter_4["SCHED_DEP_HOUR"], x_train_inter_4["DISTANCE"], c=y_train_inter_4, s=10, cmap='gray')

"""**INTERPRETATION:**

Interpretation:

From 1.4.2 we can interpret that majority of flight count (i.e flights schedule per hour ) are below 300 .

From 1.4.3 we can interpret that there is expnentialy increase of schedule arr hour with increase in schedule departure hour .

From 1.4.3 we can interpret that there majority of flight are schedule below distance 300 .

<div class='exercise-r'>

**1.5**

</div>
"""

def progressbar(n_step, n_total):
    """Prints self-updating progress bar to stdout to track for-loop progress

    There are entire 3rd-party libraries dedicated to custom progress-bars.
    A simple function like this is often more than enough to get the job done.

    :param n_total: total number of expected for-loop iterations
    :type n_total: int
    :param n_step: current iteration number, starting at 0
    :type n_step: int

    .. example::

        for i in range(n_iterations):
            progressbar(i, n_iterations)

    .. source:

        This function is a simplified version of code found here:
        https://stackoverflow.com/questions/3160699/python-progress-bar/15860757#15860757
    """
    n_step = n_step + 1
    barlen = 50
    progress = n_step / n_total
    block = int(round(barlen * progress))
    status = ""
    if n_step == n_total:
        status = "Done...\r\n\n"
    text = "\r [{0}] {1}/{2} {3}".format(
        "=" * block + "-" * (barlen - block),
        n_step,
        n_total,
        status,
    )
    sys.stdout.write(text)
    sys.stdout.flush()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Bootstrap and train your networks and get predictions on fixed X test
# # your code here
# x_test_boot = x_test[8:17]
# x_test_boot = scaler.transform(x_test_boot)

# change flag to 1 to run the below cell, it takes a lot of time to run
flag = 1

# generate your plot
# your code here
if flag:
  boot_pred = []
  models = []
  n_iterations = 50
  for i in range(n_iterations):
      progressbar(i, n_iterations)
      x_bs, y_bs = resample(x_train_scaled, y_train, replace=True)
      #cloned_model = clone_model(NN_model)
      model=tf.keras.models.Sequential(name=f"NN_model_{i + 1}")
      model.add(tf.keras.layers.Dense(n_hidden,input_dim=808,activation = 'relu',name='hidden1'))
      model.add(tf.keras.layers.Dense(n_hidden,activation = 'relu',name='hidden2'))
      model.add(tf.keras.layers.Dense(n_output, activation = 'sigmoid',name='output'))
      model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
      model.fit(x_bs, y_bs, epochs = 10, batch_size = 10,verbose=0,validation_split=0.2)
      models.append(model)
      # # make predictions
      y_hat = model.predict(x_test_boot).reshape(-1)
      # evaluate model
      boot_pred.append(list(y_hat))

boot_pred_T = list(map(list, zip(*boot_pred)))
boot_pred_T = np.round(np.array(boot_pred_T), 3)

# generate your plot
# your code here
fig, axes = plt.subplots(4, 2, figsize=(9, 15))
ci_list = []
for i, ax in enumerate(axes.flat):
  arr = sorted(boot_pred_T[i])
  # print(np.round(np.array(arr), 3))
  ci_vals = (np.percentile(arr,2.5),np.percentile(arr,97.5))
  # ci_list.append(ci_vals)
  ax.hist(arr)
  ax.axvline(ci_vals[0], 0, 1, color = 'y', label='left interval')
  ax.axvline(ci_vals[1], 0, 1, color = 'r', label='right interval')
  ax.legend(loc='best')
  #plot_simulation(i, axes[i], arr, ci_vals)
fig.tight_layout(rect=[0, 0.03, 1, 0.95])
fig.suptitle('Confidence interval of test data')
fig.show()

arr1 = boot_pred_T[0]
arr1.sort()
ci_vals = (np.percentile(arr1,2.5), np.percentile(arr1,97.5))
plt.hist(arr1, bins=20, density='fill')
plt.axvline(ci_vals[0], 0, 1, color = 'y')
plt.axvline(ci_vals[1], 0, 1, color = 'r')

# your code here
boot_preds_full = []
for model in models:

  # make predictions
  y_hat = model.predict(x_test_scaled).reshape(-1)
  # evaluate model
  boot_preds_full.append(list(y_hat))

"""**INTERPRETATION:**

*your answer here*

<div class='exercise-r'>

**1.6**

</div>
"""

# Transposing the list of lists
boot_preds_full_T = list(map(list, zip(*boot_preds_full)))

PPR = []
for preds in boot_preds_full_T:
  arr = (np.array(preds) > 0.5)  * 1
  count_one = sum(arr == 1)
  count_zero = sum(arr == 0)
  ppr= (max(count_one, count_zero) / n_iterations)-0.5
  ppr=abs(ppr)
  PPR.append(ppr)

plt.hist(PPR)
plt.xlabel("PPR values")
plt.ylabel("Frequency")
plt.title("PPR Values distribution")

boot_pred_val=np.array(boot_preds_full_T).mean(axis=1)

boot_pred_val=(boot_pred_val>0.5)*1

# ppr_vals = np.linspace(0.1, 0.5, 20)
# abstrain_accuracies = []
# abstrain_test = []
# for ppr in PPR:
#   abstrain_map = np.array(PPR) < ppr
#   abstrain_accuracies.append(accuracy_score(boot_pred_val[abstrain_map], y_test[abstrain_map]))
#   abstrain_test.append(sum(abstrain_map) / x_test_scaled.shape[0])
#abstain model
ppr_thresh = np.linspace(0.1,0.5,50)
abst_accuracies = []
abst_test = []
for val in ppr_thresh:
  abst_map = np.array(PPR) < val
  X_test_abst = x_test[abst_map]
  y_test_abst = y_test[abst_map]
  abst_accuracies.append(model.evaluate(X_test_abst, y_test_abst)[1])
  abst_test.append(sum(abst_map) / x_test.shape[1])
plt.plot(ppr_thresh,abst_test)

"""**INTERPRETATION:**

```
# This is formatted as code
```

As the PPR value increases the percentage of pridicted probability decreases, as shown in abstain analysis.

<div class="alert alert-block alert-danger" style="color:black;background-color:#E7F4FA">

<h1>PART 2.1 [30 pts]: Kannada MNIST Kaggle competition using ANNs </h1>


<a id="part2.1intro"></a>
<h2> Problem Statement </h2>

ANNs can be prone to overfitting, where they learn specific patterns present in the training data, but the patterns do not generalize to new data.

There are several methods used to improve ANN generalization.

One approach is to use an architecture just barely wide or deep enough to fit the data. The idea here is that smaller networks are less expressive and thus less able to overfit the data.

However, it is difficult to know a priori the correct size of the ANN, and it is computationally costly to hunt for the correct size. Given this, other methodologies are used to prevent overfitting and improve ANNs' generalizability. These methodologies, like other techniques that combat overfitting, fall under the umbrella term of "regularization".

In this problem, you are asked to regularize a network of a given architecture.

<a id="part2.1about"></a>

<h3> The Kannada MNIST Dataset </h3>

<img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3630446%2F1e01bcc28b5ccb7ad38a4ffefb13cde0%2Fwondu.png?generation=1603204077179447&alt=media" style="float:right">

For this problem, we will be working with a modified version of [Kannada MNIST dataset](https://arxiv.org/pdf/1908.01242.pdf) , which is a large database of handwritten digits in the indigenous language *Kannada*.

This dataset consists of 60,000 28x28 grayscale images of the ten digits, along with a test set of 10,000 images.

For this homework, we will simplify the problem by only use the digits labeled `0` and `1` owing to the similarity of the two symbols, and we want to use a total of 1200 samples for training (this includes the data you will use for validation).

To understand the dataset better, we recommend this [article](https://towardsdatascience.com/a-new-handwritten-digits-dataset-in-ml-town-kannada-mnist-69df0f2d1456) by Vinay Prabhu, the curator of the dataset.

<a id="part2data"></a>

<h3> Downloading the Data Files </h3>

Please download all files from Kaggle [using this link](https://www.kaggle.com/c/hw1ai2c3/data).

Here's a brief description of the available files:

- `kmnist_train.csv` is our training dataset and the last column contains our response class. The 784 other columns correspond to the pixel values of the 28x28 dimension image.

Class 0 means a sample is the handwritten digit `0` and class 1 means a sample is the handwritten digit `1` in the Kannada language.  

- `kmnist_test.csv` has a structure similar to `kmnist_train.csv`, however the class label column is NOT included in with the test set. `kmnist_test.csv` has 2000 samples.

Kaggle leaderboard scores are accuracy scores calculated by Kaggle when you upload your predictions on this test set.

- `sample_submission.csv` is the format that kaggle will accept.

<a id="part2.1kaggle"></a>

<h3> AI2-C2 Homework Kaggle Competition </h3>

You need to create an account on Kaggle and join the competition via this [link](https://www.kaggle.com/t/411d852ead864884a0b45eff201fa1f0). **This is a limited participation competition. Please DO NOT share this link.**

For more information on the rules governing this Kaggle competition, **please [see question 2.1.3 below](#part2_3).**

</div>

<div class="alert alert-block alert-danger" style="color:black;background-color:#E7F4FA">

<h2>PART 2.1 Questions</h2>

**2.1.1 [5 points]** **Get the data:**

- Download data from the competition page.
- We will utilize `kmnist_test.csv` in question 2.1.3.4 only.
- Load the data and use the matplotlib function `imshow` to display a handwritten 0 and a handwritten 1.

**2.1.2 [10 points]** **Overfit an ANN:**

Build a fully-connected network (FCN) with the architecture given below using `tensorflow.keras` and assign it to a variable called `model_overfit`:

- Number of hidden layers: 3
- Nodes per hidden layer: 100, 100, 100
- Activation function: ReLU
- Loss function: binary_crossentropy
- Output unit: Sigmoid
- Optimizer: adam (use the defaults; no other tuning)
- Epochs: no more than 2,000
- Batch size: 128
- Validation size: 0.3

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3630446%2F6a491ff8d4ff590dc8ded9a25461cd4b%2FScreenshot%202020-10-20%20at%209.42.36%20PM.png?generation=1603210420701577&alt=media)
    
This ANN, when trained on the dataset, will overfit to the training set. Plot the training accuracy and validation accuracy (the x-axis should represent the number of epochs, and the y-axis should represent the accuracy). Explain how you can tell the model is overfitting.

<a id="part2_3"></a>

**2.1.3 [15 points]** **Regularize overfit network:**

Create an ANN that doesn't overfit and compete on Kaggle.

**DON'TS**

**Don't change the architecture**. In other words, keep the number of layers, number of nodes, activation function,  loss function and output unit the same. **No CNNs/RNNs/enhancements allowed for the competition.**

    
**NOTE**: We strongly discourage you to use a different training set than the one provided to you (Data augmentation is allowed). If the test set accuracy of your model in this notebook is significantly different than your kaggle submission score, you will receive zero credit for this segment of the homework.

    
**DOS**

You can change the number of epochs (max 2000), batch size, optimizer, and of course, add elements that can help to regularize (e.g., dropout, L2 norm, etc.). You can also do data augmentation.


- **2.1.3.1** Display your model summary and your training and validation accuracy and loss.


- **2.1.3.2** Print the difference between the training and validation accuracies and the difference between the training and validation losses for the final trained epoch used by your model.


- **2.1.3.3** Plot the training accuracy and validation accuracy as a function of epochs.


- **2.1.3.4** Generate your test set class predictions using your regularized model. Save those predictions to a `.csv` formatted file. Submit that `.csv` file to this Kaggle Competition for leaderboard scoring.


- **2.1.3.5** **Specify your Kaggle name that you have used on the leaderboard**. *We can't give you credit without this.*


    
**IMPORTANT NOTES ABOUT SCORING**:

- The **public leaderboard** on kaggle only displays your performance on 50% of the test set.


- After the competition is complete, the **private leaderboard** will show your performance on the FULL test set.
    
Only the **top 5** competitors (as ranked on the hidden private leaderboard) will be eligible for full credit on question 2.1.3 (out of **15 points**). Remaining competitors will be scored out of **10 points** only for 2.1.3.


**ADDITIONAL RULES:**

- Multiple Kaggle submissions are permitted, **just note** that you will need to choose, on Kaggle, which submission shall be used for final scoring.


- The version of your final notebook submitted on edStem **must contain the same model** used to generate to your chosen Kaggle submission.


- **Please do not manually label your submissions.** In other words, the labels should only be the outcome of your model.


- **No external data are allowed, please only use the KMNIST training data downloaded via the link above for training your model.**


- **Do not** create multiple accounts on Kaggle.

</div>

<a id="part2.1solutions"></a>

## PART 2.1 Solutions

<div class='exercise-r'>

**2.1.1**
    
</div>
"""

df_train=pd.read_csv('kmnist_train.csv')
df_test=pd.read_csv('kmnist_test.csv')
df_test

trainX = (df_train.iloc[:,:-1].values).astype('float32')
trainY = (df_train.iloc[:,-1].values).astype('int32')
testX = (df_test.iloc[:,:].values).astype('float32')

print(trainX.shape[1],trainY.shape[0])
print(testX.shape[1])

X_train_1 = trainX.reshape(trainX.shape[0],28,28)
#print(X_train[2])

for i in range(1,5):
    plt.subplot(219+(i+1))    #plt.subplot(329+(i+1))
    plt.imshow(X_train_1[i],cmap=plt.get_cmap('gray'))
    plt.title(y_train[i])

X_train = trainX.reshape(X_train.shape[0],28,28)
X_test = testX.reshape(X_test.shape[0],28,28)
print(X_train.shape)
print(X_test.shape)

"""<div class='exercise-r'>

**2.1.2**
    
</div>
"""

x_train, x_test, y_train, y_test = train_test_split(trainX, trainY, train_size=0.77, random_state=42)

##########
# your code here
# Building an unregularized NN.
# Initialise the NN, give it an appropriate name
# for the ease of reading
# The FCNN has 3 hidden layers,
model_1 = tf.keras.Sequential(name="Unreg_FCNN")

# Add 5 hidden layers with 100 neurons each
# tanh is the activation for the first layer
# relu is the activation for all other layers
#model_1.add(tf.keras.layers.InputLayer(784 ))
model_1.add(tf.keras.layers.Dense(100, activation ='relu',input_shape = (784,)))
model_1.add(tf.keras.layers.Dense(100, activation ='relu'))
model_1.add(tf.keras.layers.Dense(100, activation ='relu'))
#model_1.add(tf.keras.layers.Dense(100, activation ='relu'))

#model_1.add(tf.keras.layers.Dense(100, activation ='relu'))


# Add the output layer with one neuron and linear activation
model_1.add(tf.keras.layers.Dense(1 , activation = 'sigmoid'))

# View the model summary
model_1.summary()

model_1.compile(optimizer = 'adam',loss='binary_crossentropy',
            metrics=['accuracy','mse'])

history_1 = model_1.fit(x_train,y_train,batch_size =128, epochs =1500, validation_split = 0.3 ,verbose =0 )

# Helper function to plot the data
# Plot the MSE of the model
plt.rcParams["figure.figsize"] = (10,8)
plt.title("Unregularized model")
plt.semilogy(history_1.history['loss'], label='Train Loss', color='#FF9A98')
plt.semilogy(history_1.history['val_loss'],  label='Validation Loss', color='#75B594')
plt.legend()

# Set the axes labels
plt.xlabel('Epochs')
plt.ylabel('Log MSE Loss')
plt.legend()
plt.show()

y_pred = model_1.predict(testX)

# Use the model above to predict for x_text
y_pred_test = model_1.predict(x_test)

# Compute the test MSE
#mse = model_1.evaluate(x_test , y_test)

mse = mean_squared_error(y_pred_test, y_test)
mse

# your code here

"""**2.1.3**

**INTERPRETATION**


As shown in  the figure the validation loss and training loss has large difference. Therefore it could be said that the model without any regularization is overfitting.
"""

# your code here
##########
# your code here
# Building an unregularized NN.
# Initialise the NN, give it an appropriate name
# for the ease of reading
# The FCNN has 3 hidden layers,
model_2 = tf.keras.Sequential()
l2 = regularizers.l2(l2 = 0.1)

# Add 5 hidden layers with 100 neurons each
# tanh is the activation for the first layer
# relu is the activation for all other layers
#model_2.add(tf.keras.layers.InputLayer(784 ))
model_2.add(tf.keras.layers.Dense(100,kernel_regularizer=l2, activation ='relu', input_shape = (784,)))
model_2.add(tf.keras.layers.Dense(100,kernel_regularizer=l2, activation ='relu'))
model_2.add(tf.keras.layers.Dense(100,kernel_regularizer=l2, activation ='relu'))
#model_2.add(tf.keras.layers.Dense(100, activation ='relu',kernel_regularizer=l2))

#model_1.add(tf.keras.layers.Dense(100, activation ='relu'))


# Add the output layer with one neuron and linear activation
model_2.add(tf.keras.layers.Dense(1 , activation = 'sigmoid'))

# View the model summary
model_2.summary()

callback = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",min_delta=0.01,patience=20,verbose=0
)

# Compile the model with MSE as loss and Adam optimizer
# with learning rate as 0.001
model_2.compile(optimizer = 'adam',loss='binary_crossentropy',
            metrics=['mse' , 'accuracy'])

# Save the history about the model after fitting on the train data
# Use 0.2 as the validation split with 1500 epochs and batch size of 10 ,
history_2 = model_2.fit(x_train,y_train , batch_size =128 ,callbacks=[callback], epochs = 1500 ,validation_split= 0.3 , verbose = 0)

# Helper function to plot the data
# Plot the MSE of the model
plt.rcParams["figure.figsize"] = (10,8)
plt.title("l2regularized model")
plt.semilogy(history_2.history['loss'], label='Train Loss', color='#FF9A98')
plt.semilogy(history_2.history['val_loss'],  label='Validation Loss', color='#75B594')
plt.legend()

# Set the axes labels
plt.xlabel('Epochs')
plt.ylabel('MSE Loss')
plt.legend()
plt.show()

# Use the regularised model above to predict for x_b
# (used exclusively for plotting)
y_l2_regularized_pred = model_2.predict(testX)

# Use the regularised model above to predict for x_text
y_l2_pred_test = model_2.predict(x_test)

# Compute the test MSE by predicting on the test data
#mse_l2 = model_2.evaluate(x_test,y_test)
mse2= mean_squared_error(y_l2_pred_test,y_test)
mse2

"""<div class='exercise-r'>

**2.1.3.2**
    
</div>
"""

# your code here

# Defining a function to plot the the trainning loss and validation loss And training accuracy and validation accuracy as a fuction of Epochs

def plot_history(history, name):
    with plt.xkcd(scale=0.2):
      fig, ax = plt.subplots(1,2, figsize=(12,6))
      for i, metric in enumerate(['loss', 'accuracy']):
          ax[i].plot(history.history[metric], label='Train', color='#EFAEA4',linewidth=3)
          ax[i].plot(history.history[f'val_{metric}'], label='Validation', color='#B2D7D0',linewidth=3)
          if metric == 'accuracy':
            ax[i].axhline(0.5, color='#8d021f', ls='--', label='Trivial accuracy')
            ax[i].set_ylabel("Accuracy", fontsize=14)
          else:
            ax[i].set_ylabel("Loss", fontsize=14)
          ax[i].set_xlabel('Epoch', fontsize=14)

      plt.suptitle(f'{name} Training', y=1.05, fontsize=16)
      plt.legend(loc='best')
      plt.tight_layout()

# Using the plot history functionto plot the data
plot_history(history_2, 'Epoch Loss and Epoch Accuracy plot')

"""<div class='exercise-r'>

**2.1.3.3**
    
</div>
"""

# your code here
# your code here
# Helper function to plot the data
# Plot the MSE of the model
plt.rcParams["figure.figsize"] = (10,8)
plt.title("Unregularized model")
plt.semilogy(history_1.history['loss'], label='Train Loss', color='#FF9A98')
plt.semilogy(history_1.history['val_loss'],  label='Validation Loss', color='#75B594')
plt.legend()

# Set the axes labels
plt.xlabel('Epochs')
plt.ylabel('Log MSE Loss')
plt.legend()
plt.show()

"""<div class='exercise-r'>

**2.1.3.4**
    
</div>
"""

len(y_l2_regularized_pred)

# your code here
df23=pd.DataFrame(y_l2_regularized_pred)
def create_download_link( df, title = "Download CSV file", filename = "y_predicted.csv"):
    csv = df.to_csv()
    b64 = base64.b64encode(csv.encode())
    payload = b64.decode()
    html = '<a download="{filename}" href="data:text/csv;base64,{payload}" target="_blank">{title}</a>'
    html = html.format(payload=payload,title=title,filename=filename)
    return HTML(html)

create_download_link(df23)

"""<div class='exercise-r'>

**2.1.3.5**
    
</div>

**YOUR KAGGLE LEADERBOARD NAME:**

Devendra Veerelli

<div class="alert alert-block alert-danger" style="color:black;background-color:#E7F4FA">

<h1>PART 2.2 [30points]: KMNIST Classification using CNNs</h1>

In this part of Homework, you will now contruct a CNN-based model in order to best classify the Kannada MNIST dataset.

**2.2.1 [5 points]** Examine the dataset and prepare the data by appropriately standardizing, reshaping and type-checking.

**2.2.2 [20 points]** Construct a simple CNN model - with not more than 10 layers. Please ensure that you use the following layers/parameters in order to contruct the model -
1. Maxpooling
2. Dense layers
3. Regularization methods such as Adam, Drop out, Batch Normalization etc.

**2.2.3 [5 points]** Perform error analysis on the predictions of your model and report classification accuracy. This should also include loss plots that allow for comparision of the model performance across the epochs. Conclusively, provide a detailed inference of why certain misclassifications would have taken place.



</div>

<a id="part2.2solutions"></a>

## PART 2.2 Solutions

**2.2.1**
"""

X_train = (df_train.iloc[:,:-1].values).astype('float32')
y_train = (df_train.iloc[:,-1].values).astype('int32')
X_test = (df_test.iloc[:,:].values).astype('float32')

# summarize dataset shape
X=X_train
print('Train', X_train.shape, y_train.shape)
print('Test', (X_test.shape, y_test.shape))
# summarize pixel values
print('Train', X.min(), X.max(), X.mean(), X.std())
print('Test', X_test.min(), X_test.max(), X_test.mean(), X_test.std())

meanpx = X_train.mean().astype(np.float32)
stdpx = X_train.std().astype(np.float32)

def standardize(x):
    return (x-meanpx)/stdpx

from keras.utils.np_utils import to_categorical
y_train = to_categorical(y_train)
num_classes = y_train.shape[1]
num_classes

plt.title(y_train[1])
plt.plot(y_train[1])
plt.xticks(range(2));

#Designing Neural Net Architecture
from keras.models import Sequential
from keras.layers.core import Lambda, Dense, Flatten, Dropout
from keras.callbacks import EarlyStopping
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
model = Sequential()
model.add(Lambda(standardize,input_shape=(28,28,1)))
model.add(Flatten())
model.add(Dense(2,activation='softmax'))

from keras import optimizers
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
from keras.preprocessing import image
img_generator = image.ImageDataGenerator()

X_train = trainX.reshape(trainX.shape[0],28,28,1)
X_test = testX.reshape(testX.shape[0],28,28,1)
X=X_train

# summarize dataset shape
print('Train', X.shape, y.shape)
print('Test', (X_test.shape, y_test.shape))
# summarize pixel values
print('Train', X.min(), X.max(), X.mean(), X.std())
print('Test', X_test.min(), X_test.max(), X_test.mean(), X_test.std())

trainX.shape

testX.shape

trainY.shape

# confirming scale of pixel values
print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))
print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))

# convert from integers to floats
trainX = trainX.astype('float32')
# calculate global mean and standard deviation
mean, std = trainX.mean(), trainX.std()
print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))
# global standardization of pixels
trainX = (trainX - mean) / std
# clip pixel values to [-1,1]
trainX = clip(trainX, -1.0, 1.0)
# shift from [-1,1] to [0,1] with 0.5 mean
trainX = (trainX + 1.0) / 2.0
# confirm it had the desired effect
mean, std =trainX.mean(), trainX.std()
print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))
print('Min: %.3f, Max: %.3f' % (trainX.min(), trainX.max()))

# convert from integers to floats
testX = testX.astype('float32')
# calculate global mean and standard deviation
mean, std = testX.mean(), testX.std()
print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))
# global standardization of pixels
testX = (testX - mean) / std
# clip pixel values to [-1,1]
testX = clip(testX, -1.0, 1.0)
# shift from [-1,1] to [0,1] with 0.5 mean
testX = (testX + 1.0) / 2.0
# confirm it had the desired effect
mean, std = testX.mean(), testX.std()
print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))
print('Min: %.3f, Max: %.3f' % (testX.min(), testX.max()))

"""**2.2.2**"""

# creating the image data generator
datagen = ImageDataGenerator(validation_split=0.3)

meanpx = X_train.mean().astype(np.float32)
stdpx = X_train.std().astype(np.float32)

def standardize(x):
    return (x-meanpx)/stdpx

model = Sequential()
model.add(Lambda(standardize,input_shape=(28,28,1)))
model.add(Flatten())
model.add(Dense(2,activation='softmax'))

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

from keras.preprocessing import image
img_generator = image.ImageDataGenerator()

from sklearn.model_selection import train_test_split
X = X_train
y = y_train
X_train, X_val, y_train, y_val = train_test_split(X_train, trainY, test_size=0.30, random_state=42)
batches = img_generator.flow(X_train, y_train, batch_size=128)
val_batches=img_generator.flow(X_val, y_val, batch_size=128)

def fully_connected_layer():
    model=Sequential([
        Lambda(standardize,input_shape=(28,28,1)),
        Flatten(),
        Dense(512,activation='relu'),
        Dense(2,activation='softmax')
    ])
    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

from keras.layers import Convolution2D, MaxPooling2D

def get_cnn_model():
    model = Sequential([
        Lambda(standardize, input_shape=(28,28,1)),
        Convolution2D(32,(3,3), activation='relu'),
        Convolution2D(32,(3,3), activation='relu'),
        MaxPooling2D(),
        Convolution2D(64,(3,3), activation='relu'),
        Convolution2D(64,(3,3), activation='relu'),
        MaxPooling2D(),
        Flatten(),
        Dense(512, activation='relu'),
        Dense(2, activation='softmax')
        ])
    model.compile(optimizer='Adam', loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model= get_cnn_model()
model.optimizer.lr=0.01

gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,
                               height_shift_range=0.08, zoom_range=0.08)
batches = gen.flow(X_train, y_train, batch_size=64)
val_batches = gen.flow(X_val, y_val, batch_size=64)

model= get_bn_model()
model.optimizer.lr=0.01
model_history=model.fit(batches, steps_per_epoch=X_train.shape[0]//128, epochs=11,
                    validation_data=val_batches, validation_steps=X_train.shape[0]*0.3//128)

predictions = (model_overfit.predict(X_test) > 0.5).astype("int32")
submissions=pd.DataFrame({"ImageId": list(range(1,len(predictions)+1)),
                         "Label": predictions})
submissions.to_csv("DR.csv", index=False, header=True)

"""**2.2.3**

**Error Analysis Inference:**

By doing error analysis i found that Perform error analysis on the predictions of your model and report classification accuracy. This should also include loss plots that allow for comparision of the model performance across the epochs. Conclusively, provide a detailed inference of why certain misclassifications would have taken place
"""